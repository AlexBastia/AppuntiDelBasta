% \begin{document}
\chapter{Probabilistic approach}
Instead of trying to find the function:
\[
f: X \to Y
\]
we can compute the probability:
\[
  p: P(Y|X)
\]
this is because we just want to approximate the function

va be ripassino di probabilita' let's go 

\nt{
  Most important concepts to remember:
  \begin{itemize}
    \item Events
    \item Axioms of probability Theory
    \item Conditional Probability
    \item Independent Rules
    \item Bayes Rule
    \item Joint Probability Distribution
  \end{itemize}
}

\dfn{Random Variable}{A \textbf{random variable X} denotes an outcome about which we are
uncertain, for instance the result of a randomized experiment}

The set of all possible outcomes of a random experiment is called \textbf{sample space} and is denoted by $\Omega$. A random variable is a measurable function over $\Omega$. 

\dfn{Event}{An Event is an arbitrary subset of $\Omega$.}

\section{Axioms of Probability Theory}
\begin{itemize}
  \item $0 \leq P(A) \leq 1$
  \item $P(\Omega) = 1$
  \item $P(True)=1$ and $P(False)=0$
  \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{itemize}
\subsection{Derived Theorems}
\begin{itemize}
  \item $P(\bar{A}) = 1 - P(A)$
  \item $P(A) = P(A \cap B) + P(A \cap \bar{B})$
\end{itemize}

\section{Conditional Probability}
The conditional probability of the event A given the event B is defined as the quantity:
\dfn{Conditional Probability}{\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]}

\section{Independent Events}
Two events A and B are independent when:
\dfn{Independent Events}{\[ P(A|B) = P(A) \]}
 This is equivalent to saying that the event B has no influence over A.
\subsection{Derived Theorems}
\begin{itemize}
  \item $P(A \cap B) = P(A)P(B)$
  \item Since $P(A \cap B) = P(B \cap A)$, then $P(B|A) = P(B)$
\end{itemize}

\section{Bayes Rule}
\dfn{Bayes Rule}{\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)} \]}


% \end{document}
