% \begin{document}
\chapter{Variabili Aleatorie}
\section{Introduzione}
  Finora, abbiamo trattato solo di eventi, per i quali ci chiediamo, fatto l'esperimento aleatorio, se sono avvenuti o meno. Possiamo pensare di domandarci non se un'affermazione si realizza o meno, ma generalizzare l'idea e chiederci quale sara' la quantita' numerica aleatoria, associata quindi ad un esperimento. Vogliamo quindi formalizzare l'idea di una quantita' che dipende dall'esito di un esperimento aleatorio:
  \dfn{Variabile Aleatoria}{
    Diamo due affermazioni (come per gli eventi):
    \begin{itemize}
    \item \textbf{Affermazione}:

      Una variabile aleatoria e' un'affermazione che riguarda il risultato dell'esperimento aleatorio. Tale affermazione identifica uno e un solo numero, una volta noto l'esito. Stiamo quindi rispondendo alla domanda "Quanto vale ... ?"

      \item \textbf{Funzione}:

        Dato uno spazio di probabilita' $ (\Omega, \mathbb{P}) $ ed un insieme $ E \neq \emptyset $, si dice \textit{variabile aleatoria} ogni funzione $ X $ del tipo:
        \[
        X: \Omega \to E
        \]
        Se $ E = \mathbb{R} $, allora $ X $ e' una variabile aleatoria \textit{reale}. Puo' anche essere che $ E = \mathbb{R}^{n} $ con $ n > 1 $, e in questo caso si parla di variabili aleatorie \textit{vettoriali}.
      
    \end{itemize}
  }

  \ex{Lancio di due dadi}{
    Dato lo spazio di probabilita', definiamo una variabile aleatoria $ X $:
    \[
    X = \text{La somma dei due lanci}
    \]
    Dobbiamo, quindi, prendere l'esito dell'esperimento e sommare il valore dei due dadi. Questa operazione puo' essere vista come una funzione a cui viene passata l'esito dell'esperimento e che restituisce un numero reale:
    \begin{align*}
      X: \Omega \to \mathbb{R}
    \end{align*}
    Questa e' la definizione di variabile aleatoria come funzione.

    In questo caso, $ \Omega = \{1,...,6\}\times \{1,...,6\} = DR_{6,2} $, qundi:
    \[
      X((\omega_1, \omega_2)): \omega_1+\omega_2
    \]
  }
  \nt{
    Qualunque funzione da $ \Omega $ a $ \mathbb{R} $ e' una variabile aleatoria. Se $ \Omega $ e' piu' che numerabile sorgono dei problemi a causa dell'unione numerabile, quindi viene usata la $ \sigma $-algebra, un insieme delle parti ristretto per evitare tali problemi. 
  }

  \section{Variabili Aleatorie Costanti}
  Vediamo dei casi "banali" di variabili aleatorie per capire il loro funzionamento e come vengono definite. Iniziamo con le funzioni costanti:
  \dfn{Variabile Aleatoria Costante}{
    Una VA (variabile aleatoria) $ X $ si dice \textit{costante} se:
    \[
      \forall \omega \in \Omega.\ X(\omega) = a
    \]
    Dove $ a \in E $ e' un elemento fissato. E' definita $ \forall \Omega $, dato che e' deterministica (non dipende dall'esito dell'esperimento).
  }
  Come per gli eventi, anche le variabili aleatorie possono essere \textit{quasi} costanti:
  \dfn{Variabili Aleatorie Quasi Costanti}{
    Una VA $ X $ si dice \textit{quasi costante} se:
    \[
      \forall \omega \in \Omega.\ \mathbb{P}(X = a) = 1
    \]
  }
  \nt{
    La scrittura $ (X = a) $ e' una notazione che rappresenta l'evento $ A = \text{"Il valore di X sara' "} a $, ovvero il sottoinsieme di $ \Omega $ per cui tutti gli elementi, passati a $ X $, danno lo stesso valore $ a $, quindi:
    \[
      \mathbb{P}(X = a) \coloneq \mathbb{P}(\{\omega \in \Omega | X(\omega) = a\})
    \]
  }
  \ex{Lancio di un dado}{
    $ \Omega = \mathbb{R} $, $ \mathbb{P} $ probabilita' uniforme su $ \{1,...,6\} $ e nulla sul resto degli elementi.

    Con $ E = \mathbb{R} $, fisso $ a \in E $ e voglio costruire $ X: \Omega \to E $ tale che $ X $ e' quasi costante:
    \[
      X(\omega) = \begin{cases}
      a & \omega \in \{1,...,6\}\\
      \omega & \text{altrimenti}
      \end{cases}
    \]
    Questa e' effettivamente una VA quasi costante, dato che $ \mathbb{P}(X = a) = 1 $. Infatti abbiamo assegnato un valore costante $ a $ a tutti gli $ \omega $ la cui probabilita' non era nulla. Ricordiamoci che la notazione $ \mathbb{P}(X = a) $ puo' essere riscritta meglio come $ \mathbb{P}(\{\omega \in \Omega | X(\omega) = a\}) $, che in questo caso corrisponde con $ \mathbb{P}(\{1,...,6\}) $ che ovviamente e' uguale a 1.

    Notare che per tutti gli $ \omega $ con probabilita' nulla, il valore di $ X $ associato puo' essere qualunque cosa (non costante) e la $ X $ rimane comunque quasi costante. 
  }

  \section{Variabili Aleatorie Indicatrici (o di Bernulli)}

  \dfn{Varaibile Aleatoria Indicatirce}{
    Dato un evento $ A \subseteq \Omega $, definisco la variabile aleatoria indicatrice di $ A $ come:
    \[
      X(\omega): \mathbb{1}_A(\omega) = \begin{cases}
      1 & \omega \in A\\
      0 & \omega \notin A
      \end{cases}
    \]
  }
  Quindi, dato un evento, la VA indicatrice $ X $ ci \textit{indica} se l'esito $ \omega $ appartenga o meno all'evento. Notiamo che tutta l'informazione dell'evento $ A $ e' contenuta nella VA:
  \[
  A \rightsquigarrow \mathbb{1}_A
  \]
  Allora le VA sono \textit{generalizzazioni} del concetto di evento.

\ex{Prove ripetute e indipendenti}{
  Consideriamo uno schema di $n$ prove ripetute e indipendenti con probabilità di successo $p$, ossia uno spazio di probabilità discreto $(\Omega, P)$ in cui sono definiti $n$ eventi $C_1, \ldots, C_n$ indipendenti e con la stessa probabilità $p = P(C_i)$ (si ricordi il Paragrafo 1.3.4). Nel Paragrafo 1.3.4.3 abbiamo studiato gli eventi

  \begin{align*}
    A_k &:= \text{``esattamente $k$ prove hanno successo''}, \\
    B_\ell &:= \text{``il primo successo si verifica nella $\ell$-esima prova''},
  \end{align*}
    
  per $0 \leq k \leq n$ e $1 \leq \ell \leq n$. Introduciamo ora due variabili aleatorie
    
  \begin{align*}
    S &:= \text{``numero di successi nelle $n$ prove''}, \\
    T &:= \text{``prova in cui si ha il primo successo''},
  \end{align*}
    
  definite su $\Omega$ a valori rispettivamente in $\{0, 1, \ldots, n\}$ e in $\mathbb{N} \cup \{+\infty\}$, mediante
    
  \begin{equation}
    S(\omega) := \sum_{i=1}^{n} 1_{C_i}(\omega), \quad T(\omega) := \min\{i \in \{1, \ldots, n\} : \omega \in C_i\},
  \end{equation}
    
  con la convenzione $\min \emptyset := +\infty$. Possiamo allora esprimere gli eventi $A_k$ e $B_\ell$ nel modo seguente:
    
  \begin{equation}
    A_k = \{\omega \in \Omega : S(\omega) = k\}, \quad B_\ell = \{\omega \in \Omega : T(\omega) = \ell\}.
  \end{equation}
    
  Questo mostra che gli eventi $A_k$ e $B_\ell$ possono essere definiti in modo naturale in termini delle variabili aleatorie $S$ e $T$, specificandone un sottoinsieme di valori.
    
}

  \section{Eventi associati alle variabili aleatorie}

  Ma se io ho $ X $ variabile aleatoria, sono capace di risalire all'evento (o eventi) associati? Le variabili aleatorie sono generalizzazioni del concetto di evento, quindi data una variabile aleatoria ci sono una moltitudine di eventi associati (o generati)

  \dfn{Evento generato da una VA}{
    Sia $ X: \Omega \to E $ una VA. $\forall A \subseteq \mathbb{R} $ indichiamo con $ \{X \in A\} $ la controimmagine di $ A $ tramite $ X $:
    \[
      \{X \in A\} \coloneq X^{-1}(A) = \{\omega \in \Omega | X(\omega) \in A\}
    \]
    Quindi $ \{X \in A\} \subseteq \Omega $ e' un evento, ed e' costituito da tutti e soli gli esiti $ \omega $ per cui $ X(\omega) \in A $.

    Gli eventi di questo tipo si dicono \textit{generati da} $ X $.
  }

  \nt{
    La scrittura $ \{X = a\} $ che abbiamo usato prima e' equivalente a scrivere $ \{X \in \{a\}\} $. Allo stesso modo, possiamo considerare un intervallo di valori usando le disequazioni: $ \{X > a\} \equiv \{X \in (a,+\infty)\} $.
  }

  Segue quindi:
  \dfn{Insieme di eventi generati da una VA}{
    Data una VA $ X $, l'insieme degli eventi da essa generati si indica con:
    \[
      \sigma(X) \coloneq \{\{X \in A\} | A \subseteq \mathbb{R}\} \subseteq \powerset(\Omega)
    \]
  }

  \nt{
    $ \forall X: \Omega \to \mathbb{R} $ v.a. possiamo scrivere:
    \[
    \Omega = \{X \in \mathbb{R}\}
    \]
    \[
    \emptyset = \{X \in \emptyset\}
    \]
  }

  Calcoliamo l'insieme degli eventi generati dalle VA particolari che abbiamo visto:

  \begin{itemize}
  \item $ X $ \textbf{costante}:

    Fisso $ a \in \mathbb{R} $, tale che $ \forall \omega \in \Omega.\ X(\omega) = a $.

    $ \sigma(X) = ? $

    Fissato $ B \subseteq \mathbb{R} $, notiamo che ci sono solo due casi:
    \[
    \{X \in B\} = \begin{cases}
    \Omega & a \in B\\
    \emptyset & a \notin B
    \end{cases}
    \]
      Infatti, se $ a $ appartiene a $ B $ allora $ \forall \omega \in \Omega.\ X(\omega) \in B $ e quindi $ \{X \in B\} = \Omega $. Mentre se $ a $ non appartiene a $ B $, si ha che $ \forall \omega \in \Omega.\ X(\omega) \notin B $ e quindi $ \{X \in B\} = \emptyset $.
  \item $ X $ \textbf{indicativa}:

    Fisso $ A \subseteq \Omega $ tale che $ \forall \omega \in \Omega.\ X(\omega) = \mathbb{1}_A(\omega) $.

    $ \sigma(X) = ? $

    Fissato $ B \subseteq \mathbb{R} $, vediamo i casi:
      \[
      \{X \in B\} = \begin{cases}
      \Omega & 0 \in B \land 1 \in B\\
      \emptyset & 0 \notin B \land 1 \notin B\\
      A & 0 \notin B \land 1 \in B\\
      A^{c} & 0 \in B \land 1 \notin B
      \end{cases}
      \]
  \end{itemize}   

  \mprop{}{
    Sia $ X: \Omega \to \mathbb{R} $ VA su $ (\Omega, \mathbb{P}) $, allora $ \forall x \in \mathbb{R} $:
    \begin{enumerate}
      \item $ \mathbb{P}(\{X \geq a\}) = \mathbb{P}(\{X = a\}) + \mathbb{P}(\{X > a\}) $
      \item $ \mathbb{P}(\{X \geq a\}) = 1 - \mathbb{P}(\{X < a\}) $
    \end{enumerate}
  }
  \pf{}{
    \begin{enumerate}
      \item $ \{X \geq a\} = \{ \omega \in \Omega | X(\omega) > a \lor X(\omega) = a\} = \{X > a\} \uplus \{X = a\} $ dato che se $ X(\omega) > a $ allora $ X(\omega) \neq a $ e viceversa. Quindi l'equazione e' dimostrata per addittivita' finita.
      \item Dimostriamo che $ \{X \geq a\} $ e $ \{X < a\} $ sono complementari. Se $ X(\omega) \not\geq a $, allora $ X(\omega) < a $ e viceversa, fatto.
    \end{enumerate}
  }

   Possiamo confronare intervalli su $ \mathbb{R} $ per calcolare probailita'

 \section{Distribuzione (o legge) di una Variabile Aleatoria}

 Ora che sappiamo trovare l'evento generato da una variabile aleatoria e un sottoinsieme del suo codominio, possiamo calcolare la probabilita' di tale evento: 

 \dfn{Distribuzione di una VA}{
   Dati $ (\Omega, \mathbb{P}) $ e $ X: \Omega\to \mathbb{R} $ VA, chiamiamo legge di $ X $ la funzione (che dimostreremo essere una probabilita'):
   \begin{align*}
     \mathbb{P}_X: \powerset(\mathbb{R}) &\to [0,1]\\
     B &\mapsto \mathbb{P}(X \in B)
   \end{align*}
   Si scrive $ X \sim \mathbb{P}_X $ e si legge "$ X $ ha legge $ \mathbb{P}_X $".
 }
 La legge di una VA ne calcola quindi, dato un insieme di valori reali, la probabilita' che $ X(\omega) $ appartenga a tale intervallo.

 \nt{
   Conoscere $ \mathbb{P}_X $ $ \forall B \subseteq \mathbb{R} $ equivale a conoscere $ \mathbb{P}_X $ $ \forall I $ intervallo di $ \mathbb{R} $. (dato che ogni intervallo e' un sottoinsieme). 
 }

 Dimostreremo che la legge $ \mathbb{P}_X(\cdot) $ e' caratterizzata dalla funzione di \textit{ripartizione}
  \begin{align*}
    F_X: \mathbb{R} &\to [0,1]\\
    n &\mapsto \mathbb{P}_X((-\infty, n]) = \mathbb{P}(\{X \leq n\})
  \end{align*}

  Quindi per studiare il comportamento daela variabile aleatoria mi devo studiare la probabilita' che $ X \leq x $ per ogni $ x \in \mathbb{R} $ (forse)

  \begin{itemize}
  \item Variabili Costanti:

    $ a \in \mathbb{R}, X(\omega) = a.\ \forall \omega \in \Omega $

    \[
    B \subseteq \mathbb{R}.\ \{X \in B\} = \begin{cases}
    \Omega & a \in B\\
    \emptyset &  a \notin B
    \end{cases}
    \]
    \[
    \mathbb{P}_X(B) = \mathbb{P}(X \in B) = \begin{cases}
    1 & a \in B\\
    0 & a \notin B
    \end{cases}
    \]
      Questa e' la delta di Dirac di $ a $ valutata su $ B $
    \item Variabili Indicatrici:

      $ A \subseteq \Omega $, $ X(\omega) = \mathbb{1}_A(\omega) $
      \[
      B \subseteq \mathbb{R}, \{X \in B\} = \begin{cases}
      \Omega & 1, 0 \in B\\
      \emptyset & 1, 0 \notin B\\
      A & 1 \in B \land 0 \notin B\\
       & 
      \end{cases}
      \]
      \[
        P_X(B) = P(X \in B) = \begin{cases}
        1 & \\
        0 & \\
          P(A) & \\
          1-P(A) & 
        \end{cases}
      \]
      Questa e' una probabilita' discreta, quidni e' possibile crearla usando una combinazione lineare di delta di Dirac: 
      \[
        = P(A)\delta_1(B) + (1-P(A))\delta_0(B)
      \]
      Ovvero:
      \[
        P_X(\cdot) = P(A)\delta_1(\cdot) + (1-P(A))\delta_0(\cdot)
      \]
      Distribuzione (o legge) di Bernulli. Se la variabile aleatoria diventa piu' complicata, aumentano il numero di delta.
  \end{itemize}

  $ P_X $ contiene tutte le informazioni di $ X $, ma e' una funzione di insiemi, quindi e' complicata da calcolare.
  \nt{
    $ B \subseteq \mathbb{R} $, ma e' un sottoinsieme di reali, ...
  }
  \dfn{}{
    $ (\Omega, P) $ SP $ X: \Omega \to \mathbb{R} $, si chiama funzione di \textit{ripartizione} di $ X $:
    \[
      F_X: \mathbb{R} \to [0,1]
    \]
    \[
      x \to P_X((-\infty, x])
    \]
  }
  Ricostruisco 

  $ P_X(B) = \delta_a(B) $, $ F_X(x) = P_X((-\infty, x]) = \delta_a(\{-\infty, x]) $
  \[
  = \begin{cases}
  1 & x \geq a\\
  0 & x < a
  \end{cases}
  \]
Grafico

$ P_X(B) = P(A)\delta_1 + (1-P(A))\delta_0 $
\[
  F_X(x) = P_X((-\infty, x]) = P(A)\delta_1((-\infty, x]) +...
\]
\[
= \begin{cases}
1 & x \geq 1\\
  1-P(A) & x < 0\\
 0 & x \in [0, 1)
\end{cases}
\]
Se io ho una qulunque funzione che rispetta tali proprieta', allora e' di ripartizione

\thm{}{
  $ (\Omega, P) $ SP, $ X: \Omega \to \mathbb{R} $, $ F_X $ fdr, allora:
  \begin{itemize}
  \item $ F_X $ e' monotona crescente
  \item $ F_X $ e' continua a destra, ovvero $ \lim_{y\to x^{+}} $
  \item 
  \end{itemize}

  Vale anche il viceversa: se $ G: \mathbb{R} \to [0,1] $ verifica 1,2,3,4, allora
  \[
    \exists(\Omega, P).\ X:\Omega\to \mathbb{R}.\ G \equiv F_X
  \]
}
\mlenma{}{
  Sia $ (\Omega, P) $ SP
  $ "A_m" \up A = A_n \subseteq A_{n+1}, \bigcup_{n=1}^{\infty} A_n = A $

  allora $ \lim_{n\to+\infty} P(A_n) = P(A) $

  Stessa roba per monotona al contrario
}
\pf{}{
  Prima parte:
  \begin{itemize}
    \item Usiamo la monotonia della probabilita' $ (-\infty, x] \subseteq (-\infty, y] $
  \item Dobbiamo passare al limite dentro la probabilita' per 2,3,4. Serve la stabilita' della probabilita' per limiti monotoni
  \end{itemize}
}

La probabilita' di tutti gli intervalli si scrivono in termini di $ F_X $:
\[
  P_X((a,b]) = F_X(b) - F_X(a)
\]
\section{Variabili Aleatorie Discrete}
Possono assumere un numero finito o numerabile di valori
\dfn{}{
  $ X: \Omega  $
}


% \end{document}

\dfn{Distribuzioni di Bernulle}{
  $\P_x (\cdot) = \P(A) \delta_1(\cdot) + (1-\P(A))\delta_0(\cdot)$
}

\nt{
  $B\subseteq \mathbb{R}$
  Conoscere $\P_x(B)\forall B\in \mathbb{R}\iff \P_x(I), \forall I$ interveòòa reaòe 
}

\dfn{Funzione di ripartizione}{
  Sia $(\Omega, \P)$ uno spazione di probabilita e $X:\Omega \to \mathbb{R}$ una variabile aleatoria. È definita \textbf{funzione di ripartizione} o \textbf{CDF} di $X$ la funzione
  \[
    F_X : \mathbb{R}\to [0,1]
  \]
  Deginita da
  \begin{equation}
    F_X(x)=\P(X\leq x) = \P_X((-\infty,x]), \quad \forall x\in \mathbb{R}
  \end{equation}
  Per dire che $X$ ha una funzione di ripartizione $F_X$ scriviremeo 
  \[
    X\sim F_X
  \]
}

\nt{
  $F_X$ determina completamente la distribuzione di $X$_
  \begin{itemize}
    \item  se conosco $P_X$ allora conosco $F_X$
    \item se conosco $F_X$ allora conosco $\P_X(B)$ per ogni sottoinsieme di $B$
  \end{itemize}
}
La Shlein ci da questo teorema
\thm{Teorema di Teodoro}{
  Sia $(Ω, P)$ uno spazio di probabilit`a e $X : Ω → R$ una variabile aleatoria. La funzione di ripartizione $F_X$ di $X$ verifica le seguenti propriet`a:
  \begin{enumerate}
    \item $F_X$ è monotona crescente (non necessariamente strettamente)
    \item $F_X$ è continua a destra: 
    \[
      \lim_{y\to x+}F_X (y) = F_X(x)\forall x\in \mathbb{R}
    \]
    \item $F_X_{x\to - \infty} F_X(x)=0$
    \item $F_X_{x\to + \infty} F_X(x)=1$

  \end{enumerate}

  Vale viceversa: se $G: \mathbb{R}\to [0,1]$ verifica 1.2.3.4. $\implies \exists (\Omega, \P)\land \exists X, G=F_X$ 
}
\pf{Dimostrazione}{
  Dimostro i veri punti:
  \begin{enumerate}
    \item $(-\infty, x]\subset (-\infty, y]\implies \P((-\infty, x])\leq \P_X((-\infty, y])$. Quindi $x\leq y$
    \item Per 3, 4: serve simostrare la stababilitò della probabilità per limiti monotoni. Si noti il lemma seguente
  \end{enumerate}
}
\mlenma{LEmma}{
  Sia Sia (Ω, P) uno spazio di Probabilità
  $A_n \uparrow A$: $A_n \subset A_{n+1}, \quad \bigcup^{+\infty}_{n+1}A_n = A, \quad A_i$ eventi

  Allora 
  \[
    \lim_{n+\infty} \P(A_n) = \P(A)
  \]
  Inoltre
  \[
    A_n \downarrow A
  \]
}
\pf{Dimostrazione}{
  \begin{center}
    \includegraphics{image.png}
  \end{center}
}
