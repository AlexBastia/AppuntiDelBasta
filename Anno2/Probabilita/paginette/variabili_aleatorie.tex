% \begin{document}
\chapter{Variabili Aleatorie}
\section{Introduzione}
  Finora, abbiamo trattato solo di eventi, per i quali ci chiediamo, fatto l'esperimento aleatorio, se sono avvenuti o meno. Possiamo pensare di domandarci non se un'affermazione si realizza o meno, ma generalizzare l'idea e chiederci quale sara' la quantita' numerica aleatoria, associata quindi ad un esperimento. Vogliamo quindi formalizzare l'idea di una quantita' che dipende dall'esito di un esperimento aleatorio:
  \dfn{Variabile Aleatoria}{
    Diamo due affermazioni (come per gli eventi):
    \begin{itemize}
    \item \textbf{Affermazione}:

      Una variabile aleatoria e' un'affermazione che riguarda il risultato dell'esperimento aleatorio. Tale affermazione identifica uno e un solo numero, una volta noto l'esito. Stiamo quindi rispondendo alla domanda "Quanto vale ... ?"

      \item \textbf{Funzione}:

        Dato uno spazio di probabilita' $ (\Omega, \mathbb{P}) $ ed un insieme $ E \neq \emptyset $, si dice \textit{variabile aleatoria} ogni funzione $ X $ del tipo:
        \[
        X: \Omega \to E
        \]
        Se $ E = \mathbb{R} $, allora $ X $ e' una variabile aleatoria \textit{reale}. Puo' anche essere che $ E = \mathbb{R}^{n} $ con $ n > 1 $, e in questo caso si parla di variabili aleatorie \textit{vettoriali}.
      
    \end{itemize}
  }

  \ex{Lancio di due dadi}{
    Dato lo spazio di probabilita', definiamo una variabile aleatoria $ X $:
    \[
    X = \text{La somma dei due lanci}
    \]
    Dobbiamo, quindi, prendere l'esito dell'esperimento e sommare il valore dei due dadi. Questa operazione puo' essere vista come una funzione a cui viene passata l'esito dell'esperimento e che restituisce un numero reale:
    \begin{align*}
      X: \Omega \to \mathbb{R}
    \end{align*}
    Questa e' la definizione di variabile aleatoria come funzione.

    In questo caso, $ \Omega = \{1,...,6\}\times \{1,...,6\} = DR_{6,2} $, qundi:
    \[
      X((\omega_1, \omega_2)): \omega_1+\omega_2
    \]
  }
  \nt{
    Qualunque funzione da $ \Omega $ a $ \mathbb{R} $ e' una variabile aleatoria. Se $ \Omega $ e' piu' che numerabile sorgono dei problemi a causa dell'unione numerabile, quindi viene usata la $ \sigma $-algebra, un insieme delle parti ristretto per evitare tali problemi. 
  }

  \section{Variabili Aleatorie Costanti}
  Vediamo dei casi "banali" di variabili aleatorie per capire il loro funzionamento e come vengono definite. Iniziamo con le funzioni costanti:
  \dfn{Variabile Aleatoria Costante}{
    Una VA (variabile aleatoria) $ X $ si dice \textit{costante} se:
    \[
      \forall \omega \in \Omega.\ X(\omega) = a
    \]
    Dove $ a \in E $ e' un elemento fissato. E' definita $ \forall \Omega $, dato che e' deterministica (non dipende dall'esito dell'esperimento).
  }
  Come per gli eventi, anche le variabili aleatorie possono essere \textit{quasi} costanti:
  \dfn{Variabili Aleatorie Quasi Costanti}{
    Una VA $ X $ si dice \textit{quasi costante} se:
    \[
      \forall \omega \in \Omega.\ \mathbb{P}(X = a) = 1
    \]
  }
  \nt{
    La scrittura $ (X = a) $ e' una notazione che rappresenta l'evento $ A = \text{"Il valore di X sara' "} a $, ovvero il sottoinsieme di $ \Omega $ per cui tutti gli elementi, passati a $ X $, danno lo stesso valore $ a $, quindi:
    \[
      \mathbb{P}(X = a) \coloneq \mathbb{P}(\{\omega \in \Omega | X(\omega) = a\})
    \]
  }
  \ex{Lancio di un dado}{
    $ \Omega = \mathbb{R} $, $ \mathbb{P} $ probabilita' uniforme su $ \{1,...,6\} $ e nulla sul resto degli elementi.

    Con $ E = \mathbb{R} $, fisso $ a \in E $ e voglio costruire $ X: \Omega \to E $ tale che $ X $ e' quasi costante:
    \[
      X(\omega) = \begin{cases}
      a & \omega \in \{1,...,6\}\\
      \omega & \text{altrimenti}
      \end{cases}
    \]
    Questa e' effettivamente una VA quasi costante, dato che $ \mathbb{P}(X = a) = 1 $. Infatti abbiamo assegnato un valore costante $ a $ a tutti gli $ \omega $ la cui probabilita' non era nulla. Ricordiamoci che la notazione $ \mathbb{P}(X = a) $ puo' essere riscritta meglio come $ \mathbb{P}(\{\omega \in \Omega | X(\omega) = a\}) $, che in questo caso corrisponde con $ \mathbb{P}(\{1,...,6\}) $ che ovviamente e' uguale a 1.

    Notare che per tutti gli $ \omega $ con probabilita' nulla, il valore di $ X $ associato puo' essere qualunque cosa (non costante) e la $ X $ rimane comunque quasi costante. 
  }

  \section{Variabili Aleatorie Indicatrici (o di Bernulli)}

  \dfn{Varaibile Aleatoria Indicatirce}{
    Dato un evento $ A \subseteq \Omega $, definisco la variabile aleatoria indicatrice di $ A $ come:
    \[
      X(\omega): \mathbb{1}_A(\omega) = \begin{cases}
      1 & \omega \in A\\
      0 & \omega \notin A
      \end{cases}
    \]
  }
  Quindi, dato un evento, la VA indicatrice $ X $ ci \textit{indica} se l'esito $ \omega $ appartenga o meno all'evento. Notiamo che tutta l'informazione dell'evento $ A $ e' contenuta nella VA:
  \[
  A \rightsquigarrow \mathbb{1}_A
  \]
  Allora le VA sono \textit{generalizzazioni} del concetto di evento.

\ex{Prove ripetute e indipendenti}{
  Consideriamo uno schema di $n$ prove ripetute e indipendenti con probabilità di successo $p$, ossia uno spazio di probabilità discreto $(\Omega, P)$ in cui sono definiti $n$ eventi $C_1, \ldots, C_n$ indipendenti e con la stessa probabilità $p = P(C_i)$ (si ricordi il Paragrafo 1.3.4). Nel Paragrafo 1.3.4.3 abbiamo studiato gli eventi

  \begin{align*}
    A_k &:= \text{``esattamente $k$ prove hanno successo''}, \\
    B_\ell &:= \text{``il primo successo si verifica nella $\ell$-esima prova''},
  \end{align*}
    
  per $0 \leq k \leq n$ e $1 \leq \ell \leq n$. Introduciamo ora due variabili aleatorie
    
  \begin{align*}
    S &:= \text{``numero di successi nelle $n$ prove''}, \\
    T &:= \text{``prova in cui si ha il primo successo''},
  \end{align*}
    
  definite su $\Omega$ a valori rispettivamente in $\{0, 1, \ldots, n\}$ e in $\mathbb{N} \cup \{+\infty\}$, mediante
    
  \begin{equation}
    S(\omega) := \sum_{i=1}^{n} 1_{C_i}(\omega), \quad T(\omega) := \min\{i \in \{1, \ldots, n\} : \omega \in C_i\},
  \end{equation}
    
  con la convenzione $\min \emptyset := +\infty$. Possiamo allora esprimere gli eventi $A_k$ e $B_\ell$ nel modo seguente:
    
  \begin{equation}
    A_k = \{\omega \in \Omega : S(\omega) = k\}, \quad B_\ell = \{\omega \in \Omega : T(\omega) = \ell\}.
  \end{equation}
    
  Questo mostra che gli eventi $A_k$ e $B_\ell$ possono essere definiti in modo naturale in termini delle variabili aleatorie $S$ e $T$, specificandone un sottoinsieme di valori.
    
}

  \section{Eventi associati alle variabili aleatorie}

  Ma se io ho $ X $ variabile aleatoria, sono capace di risalire all'evento (o eventi) associati? Le variabili aleatorie sono generalizzazioni del concetto di evento, quindi data una variabile aleatoria ci sono una moltitudine di eventi associati (o generati)

  \dfn{Evento generato da una VA}{
    Sia $ X: \Omega \to E $ una VA. $\forall A \subseteq \mathbb{R} $ indichiamo con $ \{X \in A\} $ la controimmagine di $ A $ tramite $ X $:
    \[
      \{X \in A\} \coloneq X^{-1}(A) = \{\omega \in \Omega | X(\omega) \in A\}
    \]
    Quindi $ \{X \in A\} \subseteq \Omega $ e' un evento, ed e' costituito da tutti e soli gli esiti $ \omega $ per cui $ X(\omega) \in A $.

    Gli eventi di questo tipo si dicono \textit{generati da} $ X $.
  }

  \nt{
    La scrittura $ \{X = a\} $ che abbiamo usato prima e' equivalente a scrivere $ \{X \in \{a\}\} $. Allo stesso modo, possiamo considerare un intervallo di valori usando le disequazioni: $ \{X > a\} \equiv \{X \in (a,+\infty)\} $.
  }

  Segue quindi:
  \dfn{Insieme di eventi generati da una VA}{
    Data una VA $ X $, l'insieme degli eventi da essa generati si indica con:
    \[
      \sigma(X) \coloneq \{\{X \in A\} | A \subseteq \mathbb{R}\} \subseteq \powerset(\Omega)
    \]
  }

  \nt{
    $ \forall X: \Omega \to \mathbb{R} $ v.a. possiamo scrivere:
    \[
    \Omega = \{X \in \mathbb{R}\}
    \]
    \[
    \emptyset = \{X \in \emptyset\}
    \]
  }

  Calcoliamo l'insieme degli eventi generati dalle VA particolari che abbiamo visto:

  \begin{itemize}
  \item $ X $ \textbf{costante}:

    Fisso $ a \in \mathbb{R} $, tale che $ \forall \omega \in \Omega.\ X(\omega) = a $.

    $ \sigma(X) = ? $

    Fissato $ B \subseteq \mathbb{R} $, notiamo che ci sono solo due casi:
    \[
    \{X \in B\} = \begin{cases}
    \Omega & a \in B\\
    \emptyset & a \notin B
    \end{cases}
    \]
      Infatti, se $ a $ appartiene a $ B $ allora $ \forall \omega \in \Omega.\ X(\omega) \in B $ e quindi $ \{X \in B\} = \Omega $. Mentre se $ a $ non appartiene a $ B $, si ha che $ \forall \omega \in \Omega.\ X(\omega) \notin B $ e quindi $ \{X \in B\} = \emptyset $.
  \item $ X $ \textbf{indicativa}:

    Fisso $ A \subseteq \Omega $ tale che $ \forall \omega \in \Omega.\ X(\omega) = \mathbb{1}_A(\omega) $.

    $ \sigma(X) = ? $

    Fissato $ B \subseteq \mathbb{R} $, vediamo i casi:
      \[
      \{X \in B\} = \begin{cases}
      \Omega & 0 \in B \land 1 \in B\\
      \emptyset & 0 \notin B \land 1 \notin B\\
      A & 0 \notin B \land 1 \in B\\
      A^{c} & 0 \in B \land 1 \notin B
      \end{cases}
      \]
  \end{itemize}   

  \mprop{}{
    Sia $ X: \Omega \to \mathbb{R} $ VA su $ (\Omega, \mathbb{P}) $, allora $ \forall x \in \mathbb{R} $:
    \begin{enumerate}
      \item $ \mathbb{P}(\{X \geq a\}) = \mathbb{P}(\{X = a\}) + \mathbb{P}(\{X > a\}) $
      \item $ \mathbb{P}(\{X \geq a\}) = 1 - \mathbb{P}(\{X < a\}) $
    \end{enumerate}
  }
  \pf{}{
    \begin{enumerate}
      \item $ \{X \geq a\} = \{ \omega \in \Omega | X(\omega) > a \lor X(\omega) = a\} = \{X > a\} \uplus \{X = a\} $ dato che se $ X(\omega) > a $ allora $ X(\omega) \neq a $ e viceversa. Quindi l'equazione e' dimostrata per addittivita' finita.
      \item Dimostriamo che $ \{X \geq a\} $ e $ \{X < a\} $ sono complementari. Se $ X(\omega) \not\geq a $, allora $ X(\omega) < a $ e viceversa, fatto.
    \end{enumerate}
  }

   Possiamo confronare intervalli su $ \mathbb{R} $ per calcolare probailita'

 \section{Distribuzione (o legge) di una Variabile Aleatoria}

 Ora che sappiamo trovare l'evento generato da una variabile aleatoria e un sottoinsieme del suo codominio, possiamo calcolare la probabilita' di tale evento: 

 \dfn{Distribuzione di una VA}{
   Dati $ (\Omega, \mathbb{P}) $ e $ X: \Omega\to \mathbb{R} $ VA, chiamiamo legge di $ X $ la funzione (che dimostreremo essere una probabilita'):
   \begin{align*}
     \mathbb{P}_X: \powerset(\mathbb{R}) &\to [0,1]\\
     B &\mapsto \mathbb{P}(X \in B)
   \end{align*}
   Si scrive $ X \sim \mathbb{P}_X $ e si legge "$ X $ ha legge $ \mathbb{P}_X $".
 }
 La legge di una VA ne calcola quindi, dato un insieme di valori reali, la probabilita' che $ X(\omega) $ appartenga a tale intervallo.

 \nt{
   Conoscere $ \mathbb{P}_X $ $ \forall B \subseteq \mathbb{R} $ equivale a conoscere $ \mathbb{P}_X $ $ \forall I $ intervallo di $ \mathbb{R} $. (dato che ogni intervallo e' un sottoinsieme). 
 }

 Dimostreremo che la legge $ \mathbb{P}_X(\cdot) $ e' caratterizzata dalla funzione di \textit{ripartizione}
  \begin{align*}
    F_X: \mathbb{R} &\to [0,1]\\
    n &\mapsto \mathbb{P}_X((-\infty, n]) = \mathbb{P}(\{X \leq n\})
  \end{align*}

  Quindi per studiare il comportamento daela variabile aleatoria mi devo studiare la probabilita' che $ X \leq x $ per ogni $ x \in \mathbb{R} $ (forse)

  \begin{itemize}
  \item Variabili Costanti:

    $ a \in \mathbb{R}, X(\omega) = a.\ \forall \omega \in \Omega $

    \[
    B \subseteq \mathbb{R}.\ \{X \in B\} = \begin{cases}
    \Omega & a \in B\\
    \emptyset &  a \notin B
    \end{cases}
    \]
    \[
    \mathbb{P}_X(B) = \mathbb{P}(X \in B) = \begin{cases}
    1 & a \in B\\
    0 & a \notin B
    \end{cases}
    \]
      Questa e' la delta di Dirac di $ a $ valutata su $ B $
    \item Variabili Indicatrici:

      $ A \subseteq \Omega $, $ X(\omega) = \mathbb{1}_A(\omega) $
      \[
      B \subseteq \mathbb{R}, \{X \in B\} = \begin{cases}
      \Omega & 1, 0 \in B\\
      \emptyset & 1, 0 \notin B\\
      A & 1 \in B \land 0 \notin B\\
       & 
      \end{cases}
      \]
      \[
        P_X(B) = P(X \in B) = \begin{cases}
        1 & \\
        0 & \\
          P(A) & \\
          1-P(A) & 
        \end{cases}
      \]
      Questa e' una probabilita' discreta, quidni e' possibile crearla usando una combinazione lineare di delta di Dirac: 
      \[
        = P(A)\delta_1(B) + (1-P(A))\delta_0(B)
      \]
      Ovvero:
      \[
        P_X(\cdot) = P(A)\delta_1(\cdot) + (1-P(A))\delta_0(\cdot)
      \]
      Distribuzione (o legge) di Bernulli. Se la variabile aleatoria diventa piu' complicata, aumentano il numero di delta.
  \end{itemize}

  $ P_X $ contiene tutte le informazioni di $ X $, ma e' una funzione di insiemi, quindi e' complicata da calcolare.
  \nt{
    $ B \subseteq \mathbb{R} $, ma e' un sottoinsieme di reali, ...
  }
  \dfn{}{
    $ (\Omega, P) $ SP $ X: \Omega \to \mathbb{R} $, si chiama funzione di \textit{ripartizione} di $ X $:
    \[
      F_X: \mathbb{R} \to [0,1]
    \]
    \[
      x \to P_X((-\infty, x])
    \]
  }
  Ricostruisco 

  $ P_X(B) = \delta_a(B) $, $ F_X(x) = P_X((-\infty, x]) = \delta_a(\{-\infty, x]) $
  \[
  = \begin{cases}
  1 & x \geq a\\
  0 & x < a
  \end{cases}
  \]
Grafico

$ P_X(B) = P(A)\delta_1 + (1-P(A))\delta_0 $
\[
  F_X(x) = P_X((-\infty, x]) = P(A)\delta_1((-\infty, x]) +...
\]
\[
= \begin{cases}
1 & x \geq 1\\
  1-P(A) & x < 0\\
 0 & x \in [0, 1)
\end{cases}
\]
Se io ho una qulunque funzione che rispetta tali proprieta', allora e' di ripartizione

\thm{}{
  $ (\Omega, P) $ SP, $ X: \Omega \to \mathbb{R} $, $ F_X $ fdr, allora:
  \begin{itemize}
  \item $ F_X $ e' monotona crescente
  \item $ F_X $ e' continua a destra, ovvero $ \lim_{y\to x^{+}} $
  \item 
  \end{itemize}

  Vale anche il viceversa: se $ G: \mathbb{R} \to [0,1] $ verifica 1,2,3,4, allora
  \[
    \exists(\Omega, P).\ X:\Omega\to \mathbb{R}.\ G \equiv F_X
  \]
}
\mlenma{}{
  Sia $ (\Omega, P) $ SP
  $ "A_m" \up A = A_n \subseteq A_{n+1}, \bigcup_{n=1}^{\infty} A_n = A $

  allora $ \lim_{n\to+\infty} P(A_n) = P(A) $

  Stessa roba per monotona al contrario
}
\pf{}{
  Prima parte:
  \begin{itemize}
    \item Usiamo la monotonia della probabilita' $ (-\infty, x] \subseteq (-\infty, y] $
  \item Dobbiamo passare al limite dentro la probabilita' per 2,3,4. Serve la stabilita' della probabilita' per limiti monotoni
  \end{itemize}
}

La probabilita' di tutti gli intervalli si scrivono in termini di $ F_X $:
\[
  P_X((a,b]) = F_X(b) - F_X(a)
\]
\section{Variabili Aleatorie Discrete}
Possono assumere un numero finito o numerabile di valori
\dfn{}{
  $ X: \Omega  $
}


% \end{document}

\dfn{Distribuzioni di Bernulle}{
  $\P_x (\cdot) = \P(A) \delta_1(\cdot) + (1-\P(A))\delta_0(\cdot)$
}

\nt{
  $B\subseteq \mathbb{R}$
  Conoscere $\P_x(B)\forall B\in \mathbb{R}\iff \P_x(I), \forall I$ interveòòa reaòe 
}

\dfn{Funzione di ripartizione}{
  Sia $(\Omega, \P)$ uno spazione di probabilita e $X:\Omega \to \mathbb{R}$ una variabile aleatoria. È definita \textbf{funzione di ripartizione} o \textbf{CDF} di $X$ la funzione
  \[
    F_X : \mathbb{R}\to [0,1]
  \]
  Deginita da
  \begin{equation}
    F_X(x)=\P(X\leq x) = \P_X((-\infty,x]), \quad \forall x\in \mathbb{R}
  \end{equation}
  Per dire che $X$ ha una funzione di ripartizione $F_X$ scriviremeo 
  \[
    X\sim F_X
  \]
}

\nt{
  $F_X$ determina completamente la distribuzione di $X$_
  \begin{itemize}
    \item  se conosco $P_X$ allora conosco $F_X$
    \item se conosco $F_X$ allora conosco $\P_X(B)$ per ogni sottoinsieme di $B$
  \end{itemize}
}
La Shlein ci da questo teorema
\thm{Teorema di Teodoro}{
  Sia $(Ω, P)$ uno spazio di probabilit`a e $X : Ω → R$ una variabile aleatoria. La funzione di ripartizione $F_X$ di $X$ verifica le seguenti propriet`a:
  \begin{enumerate}
    \item $F_X$ è monotona crescente (non necessariamente strettamente)
    \item $F_X$ è continua a destra: 
    \[
      \lim_{y\to x+}F_X (y) = F_X(x)\forall x\in \mathbb{R}
    \]
    \item $F_X_{x\to - \infty} F_X(x)=0$
    \item $F_X_{x\to + \infty} F_X(x)=1$

  \end{enumerate}

  Vale viceversa: se $G: \mathbb{R}\to [0,1]$ verifica 1.2.3.4. $\implies \exists (\Omega, \P)\land \exists X, G=F_X$ 
}
\pf{Dimostrazione}{
  Dimostro i veri punti:
  \begin{enumerate}
    \item $(-\infty, x]\subset (-\infty, y]\implies \P((-\infty, x])\leq \P_X((-\infty, y])$. Quindi $x\leq y$
    \item Per 3, 4: serve simostrare la stababilitò della probabilità per limiti monotoni. Si noti il lemma seguente
  \end{enumerate}
}
\mlenma{LEmma}{
  Sia Sia (Ω, P) uno spazio di Probabilità
  $A_n \uparrow A$: $A_n \subset A_{n+1}, \quad \bigcup^{+\infty}_{n+1}A_n = A, \quad A_i$ eventi

  Allora 
  \[
    \lim_{n+\infty} \P(A_n) = \P(A)
  \]
  Inoltre
  \[
    A_n \downarrow A
  \]
}
\pf{Dimostrazione}{
  \begin{center}
    \includegraphics{image.png}
  \end{center}
}

Vabbè alex bello sto lemma

\thm{Teorema di equivalenza tra variabile discreta e funzione di ripartizione a gradini
}{
  Sia $(\Omega, \P)$ uno spazio di probabilità e $X:\Omega \to \mathbb{R}$ una variabile aleatoria. Allora le seguenti affermazioni sono equivalenti:
  \begin{enumerate}
    \item $X$ è una variabile aleatoria discreta con supporto $S_X$ finito e densità di probabilità $p_X$
   
    \item Esistono $x_1, x_2, \dots \in \mathbb{R}$ tali che $x_1<x_2<\dots$ e $F_X$ è una funzione a gradini con punti di salto in $x_1, x_2, \dots$
    
    del tipo
    \[
    F_X(x) =
    \begin{cases}
    0 & x < x_1, \\
    p_1 & x_1 \leq x < x_2, \\
    p_1 + p_2 & x_2 \leq x < x_3, \\
    \vdots & \vdots \\
    1 & x \geq x_n.
    \end{cases}
    \]

    % Esempio di grafico
    \begin{center} % TODO: sistemare
      
      \begin{tikzpicture}[scale=1.2]
        % Assi
        \draw[->] (-0.5, 0) -- (5.5, 0) node[right] {$x$};
        \draw[->] (0, -0.1) -- (0, 1.2) node[above] {$F_X(x)$};
        
        % Punti di salto
        \draw[thick] (0, 0) -- (1, 0);
        \draw[thick] (1, 0) -- (1, 0.3);
        \draw[thick] (1, 0.3) -- (2, 0.3);
        \draw[thick] (2, 0.3) -- (2, 0.6);
        \draw[thick] (2, 0.6) -- (3, 0.6);
        \draw[thick] (3, 0.6) -- (3, 0.8);
        \draw[thick] (3, 0.8) -- (4, 0.8);
        \draw[thick] (4, 0.8) -- (4, 1);
        \draw[thick] (4, 1) -- (5, 1);
        
        % Punti
        \filldraw[black] (1, 0.3) circle (1pt);
        \filldraw[black] (2, 0.6) circle (1pt);
        \filldraw[black] (3, 0.8) circle (1pt);
        \filldraw[black] (4, 1) circle (1pt);
        
        % Cerchi vuoti
        \draw[thick] (1, 0) circle (1pt);
        \draw[thick] (2, 0.3) circle (1pt);
        \draw[thick] (3, 0.6) circle (1pt);
        \draw[thick] (4, 0.8) circle (1pt);

        % Etichette
        \node[below] at (1, 0) {$x_1$};
        \node[below] at (2, 0) {$x_2$};
        \node[below] at (3, 0) {$x_3$};
        \node[below] at (4, 0) {$x_4$};
        \node[left] at (0, 0.3) {$p_1$};
        \node[left] at (0, 0.6) {$p_1 
        + p_2$};
        \node[left] at (0, 0.8) {$p_1 + p_2 + p_3$};
        \node[left] at (0, 1) {$1$};
      \end{tikzpicture}
    \end{enumerate}
  \end{center}

  e la cui formula per il salto della funzione di ripartizione è:
  \[
    \Delta F_X(x) = F_X(x) - F_X(x^-) = p_X(x) 
  \]
  \item se $B$ è un sottoinsieme dei possibili valori di $X$, allora:
  \begin{equation}
    \P(X\in B) = \P_X(B) = \sum_{x_i\in B}p_X(x) = \sum_{x_i\in B}\Delta F_X(x_i)
  \end{equation}
}
\subsubsection{valore atteso di una variabile aleatoria discreta}
\dfn{Valore atteso di una variabile aleatoria}{
  Se $X$ è una variabile aleatoria discreta con densità di probabilità $p_X$, allora il valore atteso di $X$ è:
  \[
    E[X] = \sum_{x\in S_X} x p_X(x)
  \]
}

\dfn{Varianza di $X$ }{
  Se $X$ è una variabile aleatoria discreta con densità di probabilità $p_X$ e valore atteso $E[X]$, allora la varianza di $X$ è:
  \[
    Var(X) = E[(X-E[X])^2] = \sum_{x\in S_X} (x-E[X])^2 p_X(x)
  \]
}

Si osservi che 
\nt{

    \[
      Var(X) = E[X^2] - E[X]^2
    \]

}

\thm{}{
  Sia $X$ una variabile aleatoria discreta con densità di probabilità $p_X$ e sia $g:\mathbb{R}\to \mathbb{R}$ una funzione. Allora il valore atteso di $g(X)$ è:
  \[
    E[g(X)] = \sum_{x\in S_X} g(x)p_X(x)
  \]
}

\pf{Dimostrazione}{

}

\subsection{Distribuzioni notevoli di variabili aleatorie discrete}
\subsubsection{attribuzione Uniforme (discreta)}

\dfn{Distribuzione uniforme discreta}{
  Una variabile aleatoria $X$ si dice avere una distribuzione uniforme discreta su un insieme di supporto $S_X = \{x_1, \dots, x_n\}$ di cardinalità $n$ se la densità di probabilità di $X$ è:
  \[
    p_X(x) = \frac{1}{n}, \quad \forall x\in S_X
  \]
}

Si può rappresentare questa distribuzione attraverso questa tabella:
\begin{center}
  \begin{tabular}{c|c|c|c|c|c}
    $X$ & $x_1$ & $x_2$ & $\dots$ & $x_n$ &  \\
    \hline
    $p_X(x)$ & $\frac{1}{n}$ & $\frac{1}{n}$ & $\dots$ & $\frac{1}{n}$ & 1\\ 
  \end{tabular}
\end{center}

In pratica il valore atteso di una variabile aleatoria con distribuzione uniforme discreta è:
\[
  E[X] = \sum_{x\in S_X} x p_X(x) = \sum_{x\in S_X} x \frac{1}{n} = \frac{1}{n}\sum_{x\in S_X} x = \frac{1}{n} \frac{n(n+1)}{2} = \frac{n+1}{2}
\]

mentre la varianza è:
\[
  Var(X) = \sum_{x\in S_X} (x-E[X])^2 p_X(x) = \frac{1}{n} \sum_{i=1}^n (x_i - E[X])^2
\]

\subsubsection{Distribuzione di Bernoulli}
\dfn{Distribuzione di Bernulli di parametro $p\in [0,1]$}{
  Una variabile aleatoria $X$ con un insieme di supporto $S_X = \{ 0,1 \}$ si dice avere una distribuzione di Bernoulli di parametro $p$ se la sua densità di probabilità è:
  \[
    p_X(x) = 
    \begin{cases}
      p & \text{se } x=1,\\
      1-p & \text{se } x=0
    \end{cases}
  \]
}
Si può rappresentare questa distribuzione attraverso questa tabella:

\begin{center}
  \begin{tabular}{c|c|c|c}
    $X$ & 0 & 1& \\
    \hline
    $p_X(x)$ & $1-p$ & $p$ & 1\\ 
  \end{tabular}
\end{center}

Si noti che le variabili aleatorie di bernulli sono tutte Varaibili aleatorie indicatrici:
\[
  X = \mathbb{1}_A
\]
\[
  X(w) = \begin{cases}
    1 & w\in A\\
    0 & w\notin A
  \end{cases} \quad X \sim B(p)
\]

In pratica il valore atteso di una variabile aleatoria con distribuzione uniforme discreta è:
\[
  E[X] = \sum_{x \in S_X} x p_X(x) = 0 \cdot (1-p) + 1 \cdot p = p
\]
Mentre la sua varianza è:
\[
  Var(X) = E[X^2] - (E[X])^2 = p - p^2 = p(1-p)
\]

Si noti Inoltre che:
\[
  E[X^2] = \sum_i x_i^2 p_X (x_i) = 0 \cdot (1-p) + 1 \cdot p = p
\]

\subsubsection{dibuzione binomiale di  parametri $p\in [0,1]$ e $n\in \mathbb{N}$}
Si consideri ora una generalizzazione della distribuzione di Bernoulli, detta distribuzione binomiale. Una variabile aleatroia $X$ ha distribuzione di Bernulli sse è una variabile aleatoria indivatrice di un qualche evento $A$. Se invece consideriamo $n$ prove ripetute e indipendenti di un esperimento di Bernoulli, allora la variabile aleatoria che conta il numero di successi ottenuti in $n$ si dice che ha una distribuzione binomiale. Avremo quindi $n$ variabili aleatrie  di Bernulli:
\[
  X_1 \sim B(p), X_2\sim B(p),\dots, X_n \sim B(p)
\]
Ora si consideri la seguente variabile aleatoria:
\[
  X =\text{“n di successi negli n esperimenti”} =X_1 + X_2 + \dots + X_n
\]

Si noti questo esempio:
  \ex{Estrazione con reimmissione da un'urna}{
    Consideriamo un'urna contenente $b$ palline bianche e $r$ palline rosse, per un totale di $b + r$ palline. Si effettuano $n$ estrazioni con reimmissione, e definiamo la variabile aleatoria $X$ come:
    \[
      X = \text{``numero di palline bianche estratte''}.
    \]
    Mostrare che X `e una variabile aleatoria discreta e determinarne supporto e densità discreta.

    
  }

  \pf{Soluxione}{
    Si ha che $S_x =\{0,1,2,\dots, n\}$. Occorre calcolare $p_X(k)$ per $k = 0,1,2,\dots, n$. Sia:
    \[
      A_k = \{ X=k \}, \quad \forall k \in S_X
    \]

    l'evento si può definire:
    \[
      A_k = \{ \text{“esattamente $k$ palline bianche estratte”} \}
    \]

    Ovviamete la probabilità di $A_k$ è:
  \[
    \P(A_k) = \binom{n}{k} p^k (1-p)^{n-k}
  \]
  Dove $p= \frac{b}{b+r}$ è la probabilità di estrarre una pallina bianca in una singola estrazione.
  Quindi 
  \[
    \P(X=k) = p_X(k) = \binom{n}{k} p^k (1-p)^{n-k} \quad k = 0,1,2,\dots, n
  \]

  Come seguirà dalla definizione, $X$ ha distribuzione binomiale di parametri $n$ e $p$, ovvero $X\sim B(n,p)$

  }

Si può arrivare cisì alla definizione di distribuzione binomiale:
\dfn{}{
  Una variabile aleatoria $X$ con un insieme di supporto $S_X = \{ 0,1, \dots, n \}$ si dice avere una distribuzione binomiale di parametri $p$ e $n$ se la sua densità di probabilità è:
  \[
    p_X(x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad \forall x \in S_X
  \]

  
  
  
  }
  riassunta nella seguente tabella:
  \begin{center}
    \begin{tabular}{c|c|c|c|c|c}
      $X$ & 0 & 1 & 2 & $\dots$ & n\\
      \hline
      $p_X(x)$ & $\binom{n}{0} p^0 (1-p)^n$ & $\binom{n}{1} p^1 (1-p)^{n-1}$ & $\binom{n}{2} p^2 (1-p)^{n-2}$ & $\dots$ & $\binom{n}{n} p^n (1-p)^0$\\ 
    \end{tabular}
  \end{center}
  In tal caso scriviamo
  \[
    X\sim B(n,p)
  \]
  \nt{
    Quando $n=1$ si ha la distribuzione di Bernoulli, ovvero $B(1,p)$
  }
  \mprop{}{
    Siano$ 0 \leq p \leq 1$, $n \in N$ e $X \sim B(n, p)$. Allora
    \[
    \begin{aligned}
      E[X] &= np\\
      Var(X) &= np(1-p)
    \end{aligned}
    \]
  }
  \pf{Dimostrazione}{
    \begin{enumerate}
      \item Calcoliamo prima l'attesa $\mathbb{E}[X]$:
      \begin{align*}
      \mathbb{E}[X] &= \sum_{k=0}^n k p_X(k) = \sum_{k=1}^n k p_X(k) \\
      &= \sum_{k=1}^n k \binom{n}{k} p^k (1-p)^{n-k} \\
      &= \sum_{k=1}^n k \frac{n!}{k!(n-k)!} p^k (1-p)^{n-k} \\
      &= \sum_{k=1}^n \frac{n!}{(k-1)!(n-k)!} p^k (1-p)^{n-k} \\
      &= n p \sum_{k=1}^n \frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1} (1-p)^{n-k} \\
      &\stackrel{h=k-1}{=} n p \sum_{h=0}^{n-1} \frac{(n-1)!}{h!(n-1-h)!} p^h (1-p)^{n-1-h} \\
      &\stackrel{\text{form. binom., Newton}}{=} n p.
      \end{align*}
      Qui abbiamo usato la formula del binomio e il teorema di Newton per concludere che:
      \[
      \sum_{h=0}^{n-1} \binom{n-1}{h} p^h (1-p)^{n-1-h} = 1.
      \]
      \item Calcoliamo ora la varianza $\text{Var}(X)$:
      dato che $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$, resta da calcolare $\mathbb{E}[X^2]$. Inoltre, $\mathbb{E}[X^2] = \mathbb{E}[X(X-1)] + \mathbb{E}[X] = \mathbb{E}[X(X-1)] + np$, quindi dobbiamo calcolare $\mathbb{E}[X(X-1)]$. Si ha che:
\begin{align*}
\mathbb{E}[X(X-1)] &= \sum_{k=0}^n k(k-1) p_X(k) = \sum_{k=2}^n k(k-1) p_X(k) \\
&= \sum_{k=2}^n k(k-1) \binom{n}{k} p^k (1-p)^{n-k} \\
&= \sum_{k=2}^n k(k-1) \frac{n!}{k!(n-k)!} p^k (1-p)^{n-k} \\
&= \sum_{k=2}^n \frac{n!}{(k-2)!(n-k)!} p^k (1-p)^{n-k} \\
&= n(n-1) p^2 \sum_{k=2}^n \frac{(n-2)!}{(k-2)!(n-k)!} p^{k-2} (1-p)^{n-k} \\
&\stackrel{h=k-2}{=} n(n-1) p^2 \sum_{h=0}^{n-2} \frac{(n-2)!}{h!(n-2-h)!} p^h (1-p)^{n-2-h} \\
&\stackrel{\text{form. binom., Newton}}{=} n(n-1) p^2.
\end{align*}
Qui abbiamo nuovamente usato la formula del binomio e il teorema di Newton per concludere che:
\[
\sum_{h=0}^{n-2} \binom{n-2}{h} p^h (1-p)^{n-2-h} = 1.
\]

    \end{enumerate}
  }