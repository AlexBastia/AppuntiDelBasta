
\documentclass{report}

\input{../LatexTemp/preamble.tex}
\input{../LatexTemp/macros}
\input{../LatexTemp/letterfonts}

\usepackage[utf8]{inputenc}

\setlength{\parindent}{0pt}

\title{\Huge{Probabilita' e Statistica}\\Appunti}
\author{\huge{Alex Bastianini}}
\date{}
\pagenumbering{gobble}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents

\pagebreak

\chapter{Introduzione}
L'esame e di 4 esrcizi con argomenti che ci sono sempre e alcuni che ruotano. Rispetto ad altri esami si aggiungono le catene di Markov ?, quindi ci sara' meno focus slu calcolo combinatorio. L'orale e' solo per chi vuole milgiorare il voto.

\section{La probabilita'}
Che cose'? E' vietato dare una definizione di "probabilita"! E' un concetto primitivo, che tutti noi conosciamo, e' una domanda che riguarda la filosofia. E' come il punto, la retta e il pinao nella geometria.

\[
\text{Domani a Bologna piove}
\]

Di questa affermazione, sappiamo dire solo quanto sia probabile che piova. Bisogna passare da una condizione di certezza (0 o 1) a un intervallo continuo $ [0,1] $. Stiamo generalizzando la logica del certo. 

Quindi $ P(A) \in [0,1] $, dove $ P(A) = 0 $ significa che non accadra' mai e $ P(A) = 1 $ significa che accade con certezza.

Come si assegna la probabilita'? Non e' una domanda che riguarda la matematica, ma la statistica. L'approccio classico e' quello frequentista, dove svolgiamo vari esperimenti aleatori e calcoliamo la probabilita come 
\[
  P(A) \approx \frac{\text{casi favorevoli}}{\text{casi possibili}}
\]
Notare che questa non e' una definizione, ma un'approssimazione. Questo e' l'approccio frequentista che funziona bene in casi semplici.

L'approccio bayesiano e' un aggiornamento all'approccio precedente aggiungendo informazioni a priori che ci permette di creare una distribuzione probabilistica. Tutto questo riguarda la statistica, a noi interessa la matematica della probabilita'.

\subsection{La matematica della probabilita'}
Assumiamo di conoscere a priori la probabilita' che accada un certo evento. La matematica studia come cambia la probabilita' quando facciamo interagire diversi eventi.

\subsection{Teoria degli insiemi}
Insieme di riferimento $ \Omega $ (omega grande) con $ \omega \in \Omega $ elemento dell'insieme. I sottoinsiemi $ A \subseteq \Omega $ (ma quando usa lo stretto intende comunque questo). $ P(\Omega) = \{A \subseteq \Omega\} $ e' l'insieme delle parti (insieme di tutti i sottoinsiemi). $ |A|, \#A $ e' la cardinalita' (numero di elementi) di un insieme finito.
 $ |P(A)| = 2^{|\Omega|} $

\subsubsection{Operazioni insiemistiche}
Dati $ A,B \in \Omega $:
\begin{itemize}
\item $ A \cup B = \{\omega \in \Omega | \omega \in A \lor \omega \in B\} $
  \item $ A \cap B = \{\omega \in \Omega | \omega \in A \land \omega \in B\} $
  \item 
\end{itemize}

Leggi di De Morgan: 
\begin{itemize}
  \item $ (A \cap B)^c = A^c \cup B^c $
  \item $ (A \cup B)^c = A^c \cap B^c $
\end{itemize}

si dimostrano usando l'assioma dell'ex. , anche se in realta' e' spesso possibile dimostrare il $ \iff $, ovvero l'uguaglianza fra due: 

\[
  \omega \in (A \cap B)^c \iff \omega \not\in A \cap B ... \text{TODO}
\]

Proprieta' distributiva: $ A \cup (B\cap C) = (A \cup B) \cap (A \cup C) $
$ A \cap (B \cup C)= (A \cap B) \cup (A \cap C ) $

Intersezione e unione numerabile: 

\begin{itemize}
  \item $ (A_i)_{i \in \mathbb{N}} $ e' una successione di insiemi
  \item $ \bigcup A_i = \{\omega \in \Omega | \exists i \in \mathbb{N} . \omega \in A_i \} $
  \item $ \bigcap A_i = \{\omega \in \Omega | \forall i \in \mathbb{N} . \omega \in A_i \} $
\end{itemize}

\section{Modello probabilistico di un esperimento aleatorio}
3 concetti primitivi (come nella geometria euclidea):
\begin{itemize}
\item esperimento aleatorio
\item esito
\item probabilita'
\end{itemize}

essendo oggetti primitivi, non ci sarebbe neanche bisogno di dare una definizione a parole, pero' facciamolo per comprendere meglio:

\begin{itemize}
\item Un esperimento aleatorio e' un esperimento di cui non si conosce il risultato con certezza
\item esito e' un ipotetico risultato dell'esperimento aleatorio
\end{itemize}

Un esempio aleatorio e' per esempio il lancio del dado, dove gli esiti sono $ \{1,2,3,4,5,6\} $ (notare che l'etichetta che diamo non e' importante, a noi importa il conteggio). 

\nt{
  In casi piu' complessi ci saranno vari sotto-esperimenti aleatori tra loro in relazione, come 10 lanci di un dato.
}

\dfn{Evento}{
  Un evento e' un'affermazione che riguarda l'ipotetico risultato dell'esperimento aleatorio di cui posso dire con certezza se e' vero o falso \textbf{solo una volta noto l'esito}.
}

Esempio: Un esp. aleatorio e' il lancio del dado

A = "esce un numero pari" e' un evento

\dfn{Spazio camipionario}{
  Si chiama spazio campionario un qualunque insieme che contiene tutti gli esiti dell'esperimento aleatorio.
}

Notare che non dice "tutti e solo tutti", quindi non ce n'e' solo uno. Tutti gli esiti sono rappresentati con un opportuno codice.

Esempio: lancio moneta

$ \Omega = \{t,c\} $, ma anche $ \Omega = \{t,c,f,g,h,...\} o \Omega = \mathbb{R} $ sono tutti spazi campionari validi.

\dfn{Esiti favorevoli}{
  Esiti per cui un evento e' vero sono detti esiti favorevoli.
}

\dfn{Evento in termine di insiemi}{
  Un evento e' un sottoinsieme degli esiti favorevoli $ \Omega $
}

Esempio: 

$ \Omega = \{1,2,3,4,5,6\} $, $ A = \text{"esce un numero pari"} $
$ A = \{2,4,6\} $

\end{document}
