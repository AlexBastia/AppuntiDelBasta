\chapter{Linguaggi liberi nondeterministici}
Fino ad ora abbiamo studiato due modi equivalenti per descrivere linguaggi: gli \textbf{automi finiti} e le \textbf{espressioni regolari}. Abbiamo anche visto le limitazioni di questi metodi, che non riescono ad accettare linguaggi, anche alcuni semplici come $ \{0^n 1^n \mid n \geq 0\} $. 

Per espandere la quantita' di linguaggi che possiamo studiare, introduciamo le cosidette \textbf{grammatiche libere (dal contesto)}, un metodo piu' potente che permette di descrivere certe proprieta' di linguaggi che hanno una struttura ricorsiva. Inizialmente queste grammatiche sono state studiate per analizzare linguaggi umani, ma piu' recentemente hanno visto svariate applicazioni, come nel caso dei \textbf{parser}, utilizzati dalla maggior parte di compilatori e interpreti per estrarre il significato dal codice. 

L'insieme dei linguaggi che possono essere riconosciute da grammatiche libere sono i \textbf{linguaggi liberi (dal contesto)}, che includono propriamente i linguaggi regolari. Per riconoscere tali linguaggi, introdurremo un nuovo tipo di automa: l'\textbf{automa a pila} (PDA - pushdown automata).

\section{Grammatiche libere}
Per qualche motivo, le grammatiche libere le abbiamo viste all'inizio, io le metterei qua ma va beh andate qui per capire cosa sono: \ref{dfn: gramLib}

\subsection{Semplificazione e forme normali}
Questa roba qua invece e' stata messa nei linguaggi liberi deterministici, secondo me ha piu' senzo metterla qua' o fare proprio un capitolo solo sulle grammatiche: \ref{semplificazioneGram}

\section{PDA}
In che modo possiamo modificare gli automi visti fin'ora (DFA/NFA) per far si che riescano a riconoscere linguaggi non-regonalari?

Vediamo ad esempio il linguaggio $ L = \{ww^R \mid w \in \{a, b\}^*\} $. Si puo' dimostrare (fallo per esercizio) che non e' un linguaggio regolare, dato che per riconoscerlo si dovrebbe \textbf{memorizzare} tutta la prima parte della parola palindroma (la cui lunghezza non e' limitata). Quindi serve una forma di memoria ausiliaria, che nei PDA e' imlementata con una \textbf{pila} con memoria illimitata. 

Essendo una pila (LIFO), ci sono certe restrizioni per come puo' essere gestita la memoria:
\begin{itemize}
  \item Si puo' leggere solo il primo elemento in cima alla pila (top)
  \item Si puo' rimuovere solo l'elemento top
  \item Si puo' aggiungere elementi solo in cima alla pila (in modo che diventino il nuovo top)
\end{itemize}

I PDA possono essere \textit{nondeterministici}, e come tali hanno una potenza espressiva maggiore rispetto ai PDA deterministici (DPDA). Dimostreremo alla fine della sezione che i PDA (nondeterministici) hanno lo stesso potere espressivo delle grammatiche libere.

\subsection{Definizione formale}
La definizione formale di un PDA e' simile a quella dei NFA, con l'aggiunta della presenza della pila. Questa pila contiene simboli di un alfabeto che puo' essere diverso rispetto a quello di input, quindi dobbiamo definire sia un alfabeto $ \Sigma $ per l'input, sia l'alfabeto $ \Gamma $ per la pila. L'operazione di transizione, che ci dice come si comporta l'automa, ha come dominio $ Q \times \Sigma_\epsilon \times \Gamma $ (dove $ \Sigma_\epsilon = \Sigma \cup \{\epsilon\} $), quindi la mossa del PDA e' determinata dallo stato corrente, dal carattere in input e dal carattere in cima alla pila. Di questi, il secondo puo' essere anche $ \epsilon $, quindi la macchina puo' fare una mossa senza leggere l'input, ma il simbolo in cima alla stack viene sempre letto (e consumato). 

Dato un input, l'automa puo' spostarsi su un nuovo stato e aggiungere un numero arbitrario di elementi alla pila (anche nessuno). Inoltre, dato che il nondeterminismo ha come conseguenza la possibilita' di avere diverse transizioni possibili dato lo stesso input, dobbiamo considerare come codominio l'insieme di tutti i possibili insiemi che hanno come elementi coppie del tipo $ Q \times \Gamma^* $, ovvero l'insieme potenza $ \mathcal{P}(Q \times \Gamma^*) $. 

\dfn{PDA}{
  Un automa a pila nondeterministico e' una 7-pla $ (Q, \Sigma, \Gamma, \delta, q_0, \bot, F) $ dove:
  \begin{itemize}
    \item $ Q $ e' un insieme finito di stati
    \item $ \Sigma $ e' un alfabeto di input finito
    \item $ \Gamma $ e' un alfabeto per la pila finito
    \item $ \delta: Q \times \Sigma_\epsilon \times \Gamma \to Q \times \Gamma^* $ e' la funzione di transizione
    \item $ q_0 $ e' lo stato iniziale
    \item $ \bot \in \Gamma $ e' il primo simbolo sulla pila
    \item $ F \subset Q $ e' l'insieme degli stati finali
  \end{itemize}

}

\subsection{Transizioni}

A ogni passo di computazione, possiamo attribuire a un PDA una \textbf{descrizione instantanea} (o configurazione) che ci dice lo stato corrente $ q \in Q $, l'input rimasto $ w \in \Sigma^* $ e la stringa sulla pila $ \beta \in \Gamma^* $ (dove l'elemento top e' il "carattere piu' a sinistra"): 
\[
(q, w, \beta) 
\]

Le mosse possono essere definite come una derivazione da una configurazione a quella successiva (indicata col simbolo $ \vdash_N $, come con gli altri automi). Mostriamo, usando l'inferenza logica, i due tipi di mossa:
\begin{enumerate}
  \item Lettura di un carattere in input ($ a \in \Sigma $):
    \[
     \frac{(q', \alpha) \in \delta(q, a, X)}{(q, a w, X \beta) \vdash_N (q', w, \alpha \beta)} 
    \]
  \item Senza lettura dell'input:
    \[
      \frac{(q', \alpha) \in \delta(q, \epsilon, X)}{(q, w, X \beta) \vdash_N (q', w, \alpha \beta)}
    \]
\end{enumerate}

Come per gli automi finiti, introduciamo anche $ \vdash^*_N $, la chiusura riflessiva e transitiva di $ \vdash_N $:
\[
  \frac{}{(q, w, \beta) \vdash^*_N (q, w, \beta)} \text{ e } \frac{(q, w, \beta) \vdash^*_N (q', w', \beta') \vdash_N (q'', w'', \beta'')}{(q, w, \beta) \vdash_N (q'', w'', \beta'')}
\]

\subsection{Linguaggio Accettato}
Ci sono diversi modi in cui possiamo determinare se una stringa e' accettata o meno da un PDA. Oltre al classico riconoscimento per stato finale, possiamo dire che una stringa e' accettata se alla fine dell'input la pila e' vuota:
\begin{itemize}
  \item $ L[N] = \{w \in \Sigma^* \mid (q_0, w, \bot) \vdash^*_N (q, \epsilon, \alpha). q \in F\} $
  \item $ P[N] = \{w \in \Sigma^* \mid (q_0, w, \bot) \vdash^*_N (q, \epsilon, \epsilon)\} $
\end{itemize}

Osserviamo che non per forza un PDA deve svuotare la pila alla fine di un input accettato, quindi in generale:
\[
  L[N] \neq P[N]
\]
Dimostriamo pero' che questi due metodi di riconoscimento hanno la stessa espressivita':
\thm{}{
  Dato un PDA $ N $ si ha che:
  \begin{itemize}
    \item Se $ L = L[N] $ e' il linguaggio riconosciuto da $ N $ per stato finale, allora $ \exists N' $ PDA tale che $ L = P[N'] $, dove $ P[N'] $ e' il linguaggio riconociuto da $ N' $ per pila vuota.
    \item Viceversa, se $ L = P[N] $ allora $ \exists N'' $ PDA tale che $ L = L[N''] $.
  \end{itemize}
  Quindi i PDA che riconoscono per stato finale e quelli che riconoscono per pila vuota sono equivalenti.
}
Vediamo prima un'osservazione che ci servira' per dimostrare questo teorema:
\nt{
  Si osservi che, se la pila viene completamente svuotata, il PDA che abbiamo definito non puo' avere altre transizioni. Questo e' perche' $ \epsilon \not\in \Gamma $, e quindi non e' neanche presente nel dominio della funzione di transizione. Quindi se la pila di un PDA e' vuota, allora si blocca.
}
Detto questo, passiamo a una dimostrazione per costruzione di entrambe gli enunciati: TODO aggiungi figure
\pf{Dimostrazione}{
  Dimostriamo (in ordine inverso) i due versi:
  \begin{itemize}
    \item Sia $ N $ un PDA che accetta un linguaggio $ L $ per pila vuota ($ L = P[N] $). Costruiamo un PDA $ N' $ che riconosca lo stesso linguaggio per stato finale. L'idea e' quella di aggiungere un elemento in fondo alla pila, in modo tale da poter riconoscere quando la pila di $ N $ si sarebbe svotata, e di aggiungere transizioni da tutti gli stati ad un nuovo stato finale. Per aggiungere l'elemento sulla pila, basta aggiungere un nuovo stato iniziale con una transizione verso il vecchio stato iniziale che non legga l'input e che aggiunga un elemento $ Z \not\in \Gamma $ sotto a $ \bot $. 

      Le  transizioni aggiuntive non leggono caratteri in input (sono nondeterministiche) e guardano se in cima alla pila e' presente l'elemento finale aggiunto inizialmente. In questo modo, se la pila non arriva mai all'ultimo elemento allora e' impossibile arrivare allo stato finale, mentre se la pila viene svuotata e' possibile spostarsi sullo stato finale. Se $ N' $ si trova nell'ultimo caso ma non ha finito di leggere la stringa, il PDA si blocca e la parola non viene accettata. Altrimenti viene riconosciuta, sse appartiene al linguaggio $ L $.
    \item Sia $ N $ un PDA che accetta un linguaggio $ L $ per stato finale ($ L = L[N] $). Costruiamo un PDA $ N'' $ che riconosca lo stesso linguaggio per pila vuota. L' idea e' simile a quella sopra: aggiungiamo un elemento $ Z \not\in \Gamma $ in fondo alla pila (sempre per evitare che la pila si svuoti, rendendo impossibili ulteriori transizioni), e aggiungiamo delle transizioni nondeterministiche, questa volta solo dagli stati finali di $ N $, che portano a uno stato da cui parte un'unica transizione verso se stesso. Questa transizione non fa altro che rimuovere elementi dalla pila senza leggere input, in modo che se $ N $ arriva ad uno stato finale dopo aver conumato tutto l'input, allora $ N'' $ ha una possibile strada che svuota completamente la pila. Altrimenti, o la pila non viene mai svuotata, oppure viene svotata ma senza consumare tutto l'input (e quindi non viene riconosciuta). Osservare che in tutte le altre transizioni non si puo' leggere $ Z $ dalla pila (dato che non appartiene all'alfabeto della pila), quindi non potra' accadere che la pila si svuoti consumando tutto l'input senza raggiungere lo stato aggiunto, riconoscendo erroneamente l'input.
  \end{itemize}
}

\section{Equivalenza fra grammatiche libere e PDA}
In questa sezione dimostreremo che i PDA e le grammatiche libere hanno lo stesso potere espressivo, ovvero che riconoscono lo stesso insieme di linguaggi. Quindi sia le grammatiche libere che i PDA riconoscono linguaggi liberi e faremo vedere come costruire un PDA equivalente partendo da una CFG (context free grammar) e viceversa. Dato che per definizione un linguaggio e' libero sse esiste una grammatica libera che lo descrive, ci riduciamo a dimostrare il seguente teorema:
\thm{}{
  Un linguaggio e' libero sse esiste un PDA che lo riconosce
}

Dobbiamo dimostrare le due direzioni. Dato che sono un po' corpose, separiamole in due lemmi:
\subsection{Da grammatica libera a PDA}
\mlenma{}{
  Dato un linguaggio libero $ L $, esiste un PDA $ N $ tale che 
  \[
    L = P[N]
  \]
}
Notare che potevamo anche scrivere $ L = L[N] $, dato che abbiamo dimostrato che i due metodi di riconoscimento hanno la stessa espressivita'. Per la dimostrazione ci e' piu' utile costruire un PDA che riconosca per pila vuota, andiamo a vedere come costruirlo:
\pf{Idea della dimostrazione}{
  Data la grammatica libera $ G $ che descrive $ L $, vogliamo costruire un PDA $ N $ che accetta un input $ w $ se esiste una derivazione di $ G $ che porta a $ w $. Ricordiamo che una derivazione e' la serie di sostituzioni che fa una grammatica, partendo dalla variabile iniziale, per generare una stringa. Ad ogni passo viene generata una \textbf{stringa intermedia} formata da terminali e non-terminali. Il compito di $ N $ e' quello di decidere se esistono una serie di sostituzioni (prese dalle regole di $ G $) che generano $ w $.

  La parte difficile e' sapere quale sostituzione e' quella giusta, dato che possono esserci piu' regole di sostituzione per una sola variabile. Fortunatamente, utilizzando il nondeterminismo possiamo semplicemente considerare tutte le opzioni come percorsi validi. 

  Allo stato iniziale, quindi, il PDA si ritrova solo il nonterminale $ S $ sulla pila. Poi passa per una serie di stringhe intermedie prima di avere solo terminali, che se combaciano con l'input significa che esiste una derivazione di $ G $ che genera $ w $ e quindi $ N $ lo accetta. Se in tutte le possibili diramazioni nondeterministiche l'input non combacia con la stringa nella pila, allora $ G $ non puo' generarlo e non viene riconosciuto da $ N $. 

  L'unico problema e' che un PDA puo' solo accedere al primo elemento della pila. Questo significa che se un non-terminale non e' top, non possiamo sostituirlo senza rimuovere tutti i terminali sopra, quindi non possiamo tenere in memoria l'intera stringa intermedia. Possiamo risolvere questo problema consumando il top ogni volta che appare un terminale che combacia con il carattere in input, passando quindi al carattere successivo. Se non combaciano, il PDA deve fare \textit{backtracking} e provare una nuova combinazione di sostituzioni. Se per tutte le combinazioni c'e' un terminale in top che non combacia con l'input, la stringa non viene accettata. 

  Notare che in questo modo, il PDA svolge una \textbf{derivazione leftmost} (\ref{dfn: derLeft}) dal simbolo iniziale all'input.
}
\pf{Dimostrazione formale}{
  Sia $ L $ un linguaggio libero. Allora per definizione esiste una grammatica $ G = (NT, T, R, S) $ che lo descrive. Vogliamo costruire un PDA $ N $ tale che $ L = P[N] $. Sia $ N = (\{q\}, T, NT \cup T, \delta, q, S, \emptyset) $. Aggiungiamo le transizioni $ \forall a \in T $, $ \forall A \in NT $:
    \begin{align*}
      \delta(q, a, a) &= \{(q, \epsilon)\}\\
      \delta(q, \epsilon, A) &= \{(q, \beta) \mid A \to \beta \in R\}
    \end{align*}
  Si puo' dimostrare per induzione sulla lunghezza dell'input che:
  \[
    S \Rightarrow_l^* w \iff (q, w, s) \vdash_N^* (q, \epsilon, \epsilon) 
  \]
}

\subsection{Da PDA a grammatica libera}
\mlenma{}{
  Dato un PDA $ N $ tale che $ L = P[N] $, possiamo costruire una grammatica libera $ G $ tale che:
  \[
    L = \mathcal{L}[G]
  \]
}
Questa direzione e' molto piu' lunga e complessa rispetto alla prima, dato che "programmare" un automa e' molto piu' semplice rispetto a "programmare" una grammatica. E piu' semplice dimostrare il lemma se consideriamo un PDA con un solo stato, quindi ci torna utile il seguente lemma:
\mlenma{}{
  Per ogni PDA $ N $, esiste un PDA $ N' $ con un solo stato tale che:
  \[
    P[N] = P[N']
  \]
}
Questo lemma ci dice che ogni PDA puo' essere trasformato in un PDA equivalente che ha un solo stato. Non lo dimostriamo perche sbattecazz.

Ora ci possiamo ricondurre a dimostrare il lemma con l'ipotesi aggiuntiva che $ N $ ha un solo stato:
\pf{Idea della dimostrazione}{
  Dato che la dimostrazione formale e' davvero lunghissima, tale da mandare in tilt anche il dio degli audiolibri detto "Il Guerriero", ne parleremo solo schematicamente.

  L'idea e' la seguente: dato un PDA $ N = (\{q\}, \Sigma, \Gamma, \delta, q, \emptyset) $ a uno stato, generiamo una grammatica libera $ G = (T, NT, R, S) $ equivalente tale che:
  \begin{align*}
    \forall a \in \Sigma_\epsilon, \forall A \in \Gamma. & (q, B_1B_2...B_k)  \in \delta(q, a, A) \text{ con } k \geq 0:\\
    & A \to aB_1B_2...B_k \in R
  \end{align*}

  Si puo' dimostrare che $ S \Rightarrow^* w \iff (q, w, s) \vdash_N^* (q, \epsilon, \epsilon) $.
}
\subsection{Relazione fra linguaggi regolari e linguaggi liberi}
Abbiamo quindi dimostrato che gli automi a pila riconoscono la classe di linguaggi liberi. Dato che gli automi finiti riconoscono i linguaggi regolari e possono essere convertiti in PDA che ignorano la pila, possiamo dire che:
\mprop{Relazione fra linguaggi regolari e linguaggi liberi}{
  I linguaggi regolari sono un sottoinsime proprio dei linguaggi liberi.
}
TODO: figura

\section{Proprieta'}
\subsection{Chiusura}
Come nei linguaggi regolari, anche i linguaggi liberi sono chiusi rispetto alle operazioni regolari:
\thm{}{
  I linguaggi liberi sono chiusi per:
  \begin{enumerate}
    \item Unione
    \item Concatenazione
    \item Ripetizione (stella di Kleene)
  \end{enumerate}
}
\pf{Dimostrazione}{
  Siano $ L_1, L_2 $ i linguaggi generati da due grammatiche libere $ G_1 = (NT_1, T_1, R_1, S_1), G_2 = (NT_2, T_2, R_2, S_2) $ e assumiamo che $ NT_1 \cap NT_2 = \emptyset $, allora:
  \begin{enumerate}
    \item \textbf{Unione:}

      Costruisco la grammatica libera $ G = (NT_1 \cup NT_2 \cup \{S\}, T_1 \cup T_2, R_1 \cup R_2 \cup \{S \to S_1 \mid S_2\}, S) $. Si puo' dimostrare che $ L(G) = L_1 \cup L_2 $.

    \item \textbf{Concatenazione:}

      Costruisco la grammatica libera $ G = (NT_1 \cup NT_2 \cup \{S\}, T_1 \cup T_2, R_1 \cup R_2 \cup \{S \to S_1S_2\}, S) $. Si puo' dimostrare che $ L(G) = L_1 \cdot L_2 $.

    \item \textbf{Ripetizione:}

      Costruisco la grammatica libera $ G = (NT_1 \cup \{S\}, T_1, R_1 \cup \{S \to \epsilon \mid S_1S\}, S) $. Si puo' dimostrare che $ L(G) = L_1^* $.
  \end{enumerate}
}
\subsection{Pumping Theorem}

